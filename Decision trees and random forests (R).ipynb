{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decion trees and random forests\n",
    "\n",
    "## Data\n",
    "\n",
    "Download the [World Value Survey](http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp) data and check out the corresponding questionnaire and codebook files to understand the dataset contents.\n",
    "\n",
    "## Overarching research question\n",
    "\n",
    "Explain what variables effect happiness (`V10`) using decision-tree learning.\n",
    "\n",
    "## Method\n",
    "\n",
    "There are many tools for running decision trees. We apply [Caret](https://topepo.github.io/caret/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new data matrix for analysis\n",
    "\n",
    "selected_keys <- c('V10', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9')\n",
    "\n",
    "full_data <- read.csv('data/wvs.csv', sep = \";\")\n",
    "\n",
    "data <- full_data[,selected_keys ]\n",
    "\n",
    "print( nrow( data ) )\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "\n",
    "data$V10 <- as.factor( data$V10 ) # Comment this over to run regression tree learning\n",
    "\n",
    "model <- train( V10 ~ ., data = data, method = 'rpart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best <- model$finalModel\n",
    "plot( best )\n",
    "text( best )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "As discussed in lecture, there are [many different metrics for evaluating the quality of a model](http://topepo.github.io/caret/measuring-performance.html). Beyond single metrics (like accuracy score, F1 score), examining the confusion matrix may be beneficial to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values <- predict( model, data )\n",
    "confusionMatrix( predicted_values, data$V10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Choose better or more interesting values to be modelled.\n",
    "* Improve data preprocessing (remove missing values etc.)\n",
    "* Apply training data - test data split in the data analysis stage. Does that improve the analysis at all?\n",
    "* Increase the maximum depth of the decision tree. Does it improve the analysis at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests -  decision trees on steroids.\n",
    "\n",
    "The challenge with decision trees - like many other machine learning algorithms - is that they run a single model on the data, relying on a single random state. This can easily lead to overfitting and bad performance [Random forests](https://topepo.github.io/caret/train-models-by-tag.html#Random_Forestl) address this issue through running an ensemble of trees, and creating a classifier through combining their diverging predictions (e.g. trough averaging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take time to run\n",
    "model <- train( V10 ~ ., data = data, method = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values <- predict( model, data )\n",
    "confusionMatrix( predicted_values, data$V10 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
